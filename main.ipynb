{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e284f34d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-12T08:05:54.838739Z",
     "iopub.status.busy": "2024-03-12T08:05:54.837891Z",
     "iopub.status.idle": "2024-03-12T08:06:01.286753Z",
     "shell.execute_reply": "2024-03-12T08:06:01.285925Z"
    },
    "papermill": {
     "duration": 6.459314,
     "end_time": "2024-03-12T08:06:01.289165",
     "exception": false,
     "start_time": "2024-03-12T08:05:54.829851",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-23T16:07:52.669642500Z",
     "start_time": "2024-03-23T16:07:52.374116200Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit, GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Configure\n",
    "\n",
    "IS_KAGGLE = False\n",
    "INPUT_PATH = Path(\"/kaggle/input\" if IS_KAGGLE else \"D:/MS/PPNCKH/Data\")\n",
    "OUTPUT_PATH = Path(\"/kaggle/output\" if IS_KAGGLE else \"D:/MS/PPNCKH/Final/output\")\n",
    "\n",
    "RE_FEATURES_EXTRACTED = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T16:07:52.686416Z",
     "start_time": "2024-03-23T16:07:52.671897300Z"
    }
   },
   "id": "e0d400ef216a62b2"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1554dda1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:06:01.303244Z",
     "iopub.status.busy": "2024-03-12T08:06:01.302953Z",
     "iopub.status.idle": "2024-03-12T08:06:01.315384Z",
     "shell.execute_reply": "2024-03-12T08:06:01.314498Z"
    },
    "papermill": {
     "duration": 0.021544,
     "end_time": "2024-03-12T08:06:01.317340",
     "exception": false,
     "start_time": "2024-03-12T08:06:01.295796",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-23T16:07:52.686416Z",
     "start_time": "2024-03-23T16:07:52.682667200Z"
    }
   },
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    \n",
    "    # Set data type\n",
    "    @staticmethod\n",
    "    def set_table_dtypes(df):\n",
    "        for col in df.columns:\n",
    "            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Int64))\n",
    "            elif col in [\"date_decision\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "            elif col[-1] in (\"P\", \"A\"):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float64))\n",
    "            elif col[-1] in (\"M\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.String))\n",
    "            elif col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "        return df\n",
    "\n",
    "    # Handle dates\n",
    "    @staticmethod\n",
    "    def handle_dates(df):\n",
    "        for col in df.columns:\n",
    "            # Extract month and weekday from date columns\n",
    "            if col[-1] in (\"D\",):\n",
    "                # Subtract the \"date_decision\" column from the column specified by the variable `col`\n",
    "                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n",
    "                # Convert the date column to total number of days since the first date\n",
    "                df = df.with_columns(pl.col(col).dt.total_days())\n",
    "        # Drop the \"date_decision\" and \"MONTH\" columns\n",
    "        df = df.drop(\"date_decision\", \"MONTH\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    # Filter columns\n",
    "    # Filter 1: Remove columns with more than 95% missing values\n",
    "    # Filter 2: Remove columns with only one unique value or more than 200 unique values\n",
    "    @staticmethod\n",
    "    def filter_cols(df):\n",
    "        for col in df.columns:\n",
    "            if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n",
    "                isnull = df[col].is_null().mean()\n",
    "\n",
    "                if isnull > 0.95:\n",
    "                    df = df.drop(col)\n",
    "\n",
    "        for col in df.columns:\n",
    "            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.String):\n",
    "                freq = df[col].n_unique()\n",
    "\n",
    "                if (freq == 1) | (freq > 200):\n",
    "                    df = df.drop(col)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aca76f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:06:01.330436Z",
     "iopub.status.busy": "2024-03-12T08:06:01.330137Z",
     "iopub.status.idle": "2024-03-12T08:06:01.340860Z",
     "shell.execute_reply": "2024-03-12T08:06:01.340160Z"
    },
    "papermill": {
     "duration": 0.019244,
     "end_time": "2024-03-12T08:06:01.342638",
     "exception": false,
     "start_time": "2024-03-12T08:06:01.323394",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-23T16:07:52.709839600Z",
     "start_time": "2024-03-23T16:07:52.690166700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate expression generator\n",
    "class Aggregator:\n",
    "    # Generate max aggregation expression for numerical columns\n",
    "    @staticmethod\n",
    "    def num_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        return expr_max\n",
    "\n",
    "    # Generate max aggregation expression for date columns\n",
    "    @staticmethod\n",
    "    def date_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"D\",)]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        return expr_max\n",
    "\n",
    "    # Generate max aggregation expression for string columns\n",
    "    @staticmethod\n",
    "    def str_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        return expr_max\n",
    "\n",
    "    # Generate max aggregation expression for other columns\n",
    "    @staticmethod\n",
    "    def other_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        return expr_max\n",
    "\n",
    "    # Generate max aggregation expression for count columns\n",
    "    @staticmethod\n",
    "    def count_expr(df):\n",
    "        cols = [col for col in df.columns if \"num_group\" in col]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        return expr_max\n",
    "\n",
    "    # Generate all aggregation expressions\n",
    "    @staticmethod\n",
    "    def get_exprs(df):\n",
    "        exprs = Aggregator.num_expr(df) + \\\n",
    "                Aggregator.date_expr(df) + \\\n",
    "                Aggregator.str_expr(df) + \\\n",
    "                Aggregator.other_expr(df) + \\\n",
    "                Aggregator.count_expr(df)\n",
    "        return exprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ab1d073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:06:01.355815Z",
     "iopub.status.busy": "2024-03-12T08:06:01.355551Z",
     "iopub.status.idle": "2024-03-12T08:06:01.362075Z",
     "shell.execute_reply": "2024-03-12T08:06:01.361342Z"
    },
    "papermill": {
     "duration": 0.01513,
     "end_time": "2024-03-12T08:06:01.363942",
     "exception": false,
     "start_time": "2024-03-12T08:06:01.348812",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-23T16:07:52.710590600Z",
     "start_time": "2024-03-23T16:07:52.697926800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read a single file and perform preprocessing\n",
    "def read_file(path, depth=None):\n",
    "    # Use Polars to read the parquet file\n",
    "    df = pl.read_parquet(path)\n",
    "    # Set the data types of the columns\n",
    "    df = df.pipe(Pipeline.set_table_dtypes)\n",
    "    # If depth is 1 or 2, group by case_id and aggregate the columns\n",
    "    if depth in [1, 2]:\n",
    "        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "    return df\n",
    "\n",
    "# Read multiple files and perform preprocessing\n",
    "def read_files(regex_path, depth=None):\n",
    "    chunks = []\n",
    "    # Use glob to find all files that match the regex pattern\n",
    "    for path in glob(str(regex_path)):\n",
    "        # Read the parquet file using Polars and set the data types\n",
    "        chunks.append(pl.read_parquet(path).pipe(Pipeline.set_table_dtypes))\n",
    "    # Concatenate the data frames vertically\n",
    "    df = pl.concat(chunks, how=\"vertical_relaxed\")\n",
    "    # If depth is 1 or 2, group by case_id and aggregate the columns\n",
    "    if depth in [1, 2]:\n",
    "        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c42148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:06:01.377135Z",
     "iopub.status.busy": "2024-03-12T08:06:01.376873Z",
     "iopub.status.idle": "2024-03-12T08:06:01.382270Z",
     "shell.execute_reply": "2024-03-12T08:06:01.381481Z"
    },
    "papermill": {
     "duration": 0.014079,
     "end_time": "2024-03-12T08:06:01.384093",
     "exception": false,
     "start_time": "2024-03-12T08:06:01.370014",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-23T16:07:52.711339900Z",
     "start_time": "2024-03-23T16:07:52.703577700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature engineering function to join the data frames and create new features\n",
    "def feature_eng(df_base, depth_0, depth_1, depth_2):\n",
    "    # Extract the month and weekday from the date_decision column\n",
    "    df_base = (\n",
    "        df_base\n",
    "        .with_columns(\n",
    "            month_decision = pl.col(\"date_decision\").dt.month(),\n",
    "            weekday_decision = pl.col(\"date_decision\").dt.weekday(),\n",
    "        )\n",
    "    )\n",
    "    # Join the data frames on the case_id column\n",
    "    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n",
    "        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n",
    "    # Handle missing values\n",
    "    df_base = df_base.pipe(Pipeline.handle_dates)\n",
    "    return df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1d01cad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:06:01.397322Z",
     "iopub.status.busy": "2024-03-12T08:06:01.397069Z",
     "iopub.status.idle": "2024-03-12T08:06:01.401771Z",
     "shell.execute_reply": "2024-03-12T08:06:01.400937Z"
    },
    "papermill": {
     "duration": 0.013488,
     "end_time": "2024-03-12T08:06:01.403708",
     "exception": false,
     "start_time": "2024-03-12T08:06:01.390220",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-23T16:07:52.712088500Z",
     "start_time": "2024-03-23T16:07:52.709089100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert Polars DataFrame to Pandas DataFrame and handle categorical columns\n",
    "def to_pandas(df_data, cat_cols=None):\n",
    "    df_data = df_data.to_pandas(use_pyarrow_extension_array=False)\n",
    "    if cat_cols is None:\n",
    "        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n",
    "    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n",
    "    return df_data, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28457c7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:06:01.417033Z",
     "iopub.status.busy": "2024-03-12T08:06:01.416778Z",
     "iopub.status.idle": "2024-03-12T08:06:01.420850Z",
     "shell.execute_reply": "2024-03-12T08:06:01.420006Z"
    },
    "papermill": {
     "duration": 0.012891,
     "end_time": "2024-03-12T08:06:01.422765",
     "exception": false,
     "start_time": "2024-03-12T08:06:01.409874",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-23T16:07:52.728364400Z",
     "start_time": "2024-03-23T16:07:52.713589900Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT            = INPUT_PATH / \"home-credit-credit-risk-model-stability\"\n",
    "TRAIN_DIR       = ROOT / \"parquet_files\" / \"train\"\n",
    "TEST_DIR        = ROOT / \"parquet_files\" / \"test\"\n",
    "SAVED_DF_TRAIN  = OUTPUT_PATH / \"df_train.parquet\"\n",
    "SAVED_DF_TEST   = OUTPUT_PATH / \"df_test.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff2b5ca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:06:01.436137Z",
     "iopub.status.busy": "2024-03-12T08:06:01.435898Z",
     "iopub.status.idle": "2024-03-12T08:06:32.912182Z",
     "shell.execute_reply": "2024-03-12T08:06:32.911365Z"
    },
    "papermill": {
     "duration": 31.4857,
     "end_time": "2024-03-12T08:06:32.914648",
     "exception": false,
     "start_time": "2024-03-12T08:06:01.428948",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-23T16:07:54.266630Z",
     "start_time": "2024-03-23T16:07:52.719855200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the saved features training data ...\n",
      "train data shape:\t (1526659, 376)\n"
     ]
    }
   ],
   "source": [
    "if RE_FEATURES_EXTRACTED or not SAVED_DF_TRAIN.exists():\n",
    "    print(\"Create features training data ...\")\n",
    "    # Read the training data\n",
    "    data_store = {\n",
    "        \"df_base\": read_file(TRAIN_DIR / \"train_base.parquet\"),\n",
    "        \"depth_0\": [\n",
    "            read_file(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n",
    "            read_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n",
    "        ],\n",
    "        \"depth_1\": [\n",
    "            read_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n",
    "            read_file(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n",
    "            read_file(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n",
    "            read_file(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n",
    "            read_file(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n",
    "            read_file(TRAIN_DIR / \"train_other_1.parquet\", 1),\n",
    "            read_file(TRAIN_DIR / \"train_person_1.parquet\", 1),\n",
    "            read_file(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n",
    "            read_file(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n",
    "        ],\n",
    "        \"depth_2\": [\n",
    "            read_file(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n",
    "        ]\n",
    "    }\n",
    "    # Feature engineering on the training data\n",
    "    df_train = feature_eng(**data_store)\n",
    "    # Save the training data\n",
    "    df_train.write_parquet(SAVED_DF_TRAIN)\n",
    "else:\n",
    "    print(\"Reading the saved features training data ...\")\n",
    "    df_train = pl.read_parquet(SAVED_DF_TRAIN)\n",
    "\n",
    "print(\"train data shape:\\t\", df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "170f08e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:06:40.033917Z",
     "iopub.status.busy": "2024-03-12T08:06:40.033606Z",
     "iopub.status.idle": "2024-03-12T08:06:40.465290Z",
     "shell.execute_reply": "2024-03-12T08:06:40.464484Z"
    },
    "papermill": {
     "duration": 0.441657,
     "end_time": "2024-03-12T08:06:40.467761",
     "exception": false,
     "start_time": "2024-03-12T08:06:40.026104",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-23T16:07:54.296155200Z",
     "start_time": "2024-03-23T16:07:54.264867600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the saved features test data ...\n",
      "test data shape:\t (10, 375)\n"
     ]
    }
   ],
   "source": [
    "if RE_FEATURES_EXTRACTED or not SAVED_DF_TEST.exists():\n",
    "    print(\"Create features test data ...\")\n",
    "    # Read the test data\n",
    "    data_store = {\n",
    "        \"df_base\": read_file(TEST_DIR / \"test_base.parquet\"),\n",
    "        \"depth_0\": [\n",
    "            read_file(TEST_DIR / \"test_static_cb_0.parquet\"),\n",
    "            read_files(TEST_DIR / \"test_static_0_*.parquet\"),\n",
    "        ],\n",
    "        \"depth_1\": [\n",
    "            read_files(TEST_DIR / \"test_applprev_1_*.parquet\", 1),\n",
    "            read_file(TEST_DIR / \"test_tax_registry_a_1.parquet\", 1),\n",
    "            read_file(TEST_DIR / \"test_tax_registry_b_1.parquet\", 1),\n",
    "            read_file(TEST_DIR / \"test_tax_registry_c_1.parquet\", 1),\n",
    "            read_file(TEST_DIR / \"test_credit_bureau_b_1.parquet\", 1),\n",
    "            read_file(TEST_DIR / \"test_other_1.parquet\", 1),\n",
    "            read_file(TEST_DIR / \"test_person_1.parquet\", 1),\n",
    "            read_file(TEST_DIR / \"test_deposit_1.parquet\", 1),\n",
    "            read_file(TEST_DIR / \"test_debitcard_1.parquet\", 1),\n",
    "        ],\n",
    "        \"depth_2\": [\n",
    "            read_file(TEST_DIR / \"test_credit_bureau_b_2.parquet\", 2),\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Feature engineering on the test data\n",
    "    df_test = feature_eng(**data_store)\n",
    "    # Save the test data\n",
    "    df_test.write_parquet(SAVED_DF_TEST)\n",
    "else:\n",
    "    print(\"Reading the saved features test data ...\")\n",
    "    df_test = pl.read_parquet(SAVED_DF_TEST)\n",
    "    \n",
    "print(\"test data shape:\\t\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0794f88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:06:40.524538Z",
     "iopub.status.busy": "2024-03-12T08:06:40.524254Z",
     "iopub.status.idle": "2024-03-12T08:06:42.696418Z",
     "shell.execute_reply": "2024-03-12T08:06:42.695465Z"
    },
    "papermill": {
     "duration": 2.181976,
     "end_time": "2024-03-12T08:06:42.698684",
     "exception": false,
     "start_time": "2024-03-12T08:06:40.516708",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-23T16:07:55.549646200Z",
     "start_time": "2024-03-23T16:07:54.289145900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:\t (1526659, 267)\n",
      "test data shape:\t (10, 266)\n"
     ]
    }
   ],
   "source": [
    "# Filter columns\n",
    "df_train = df_train.pipe(Pipeline.filter_cols)\n",
    "df_test = df_test.select([col for col in df_train.columns if col != \"target\"])\n",
    "\n",
    "print(\"train data shape:\\t\", df_train.shape)\n",
    "print(\"test data shape:\\t\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0024624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:06:42.714688Z",
     "iopub.status.busy": "2024-03-12T08:06:42.713881Z",
     "iopub.status.idle": "2024-03-12T08:06:56.514697Z",
     "shell.execute_reply": "2024-03-12T08:06:56.513881Z"
    },
    "papermill": {
     "duration": 13.810984,
     "end_time": "2024-03-12T08:06:56.517002",
     "exception": false,
     "start_time": "2024-03-12T08:06:42.706018",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-23T16:08:03.647359400Z",
     "start_time": "2024-03-23T16:07:57.464741100Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to pandas\n",
    "df_train, cat_cols = to_pandas(df_train)\n",
    "df_test, cat_cols = to_pandas(df_test, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a65bec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:06:56.532725Z",
     "iopub.status.busy": "2024-03-12T08:06:56.532067Z",
     "iopub.status.idle": "2024-03-12T08:06:56.651018Z",
     "shell.execute_reply": "2024-03-12T08:06:56.650180Z"
    },
    "papermill": {
     "duration": 0.128584,
     "end_time": "2024-03-12T08:06:56.652848",
     "exception": false,
     "start_time": "2024-03-12T08:06:56.524264",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-23T16:10:34.214575Z",
     "start_time": "2024-03-23T16:10:34.206325400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1712"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Garbage collection to free up memory\n",
    "if 'data_store' in globals():\n",
    "    del data_store\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2218e5b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:06:56.668552Z",
     "iopub.status.busy": "2024-03-12T08:06:56.667919Z",
     "iopub.status.idle": "2024-03-12T08:06:56.674204Z",
     "shell.execute_reply": "2024-03-12T08:06:56.673413Z"
    },
    "papermill": {
     "duration": 0.016032,
     "end_time": "2024-03-12T08:06:56.676150",
     "exception": false,
     "start_time": "2024-03-12T08:06:56.660118",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-23T16:10:38.580854600Z",
     "start_time": "2024-03-23T16:10:38.574107Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a custom VotingModel class, API similar to sklearn\n",
    "class VotingModel(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, estimators):\n",
    "        super().__init__()\n",
    "        self.estimators = estimators\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Average the predictions of all the estimators\n",
    "        y_preds = [estimator.predict(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Average the predicted probabilities of all the estimators\n",
    "        y_preds = [estimator.predict_proba(X) for estimator in self.estimators]\n",
    "        return np.mean(y_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7868d190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:06:56.691744Z",
     "iopub.status.busy": "2024-03-12T08:06:56.691197Z",
     "iopub.status.idle": "2024-03-12T08:28:56.319977Z",
     "shell.execute_reply": "2024-03-12T08:28:56.318901Z"
    },
    "papermill": {
     "duration": 1319.656181,
     "end_time": "2024-03-12T08:28:56.339374",
     "exception": false,
     "start_time": "2024-03-12T08:06:56.683193",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-23T18:33:55.932382500Z",
     "start_time": "2024-03-23T18:33:50.734604400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train week range:  [ 0  1  2  4  5  6  7  8 10 11 12 13 15 17 18 19 20 21 22 23 24 26 27 29\n",
      " 28 30 31 32 33 34 35 36 37 38 39 41 42 44 45 46 47 48 49 50 55 56 57 58\n",
      " 60 61 62 65 66 69 70 72 73 74 75 76 77 78 80 81 83 84 85 86 87 88 89 91]\n",
      "Valid week range:  [ 3  9 14 16 25 40 43 51 52 53 54 59 63 64 67 68 71 79 82 90]\n",
      "Train shape:  (1221056, 264)\n",
      "Valid shape:  (305603, 264)\n",
      "Train week range:  [ 1  2  3  4  5  8  9 10 11 12 13 14 16 17 19 21 22 23 24 25 26 27 29 28\n",
      " 30 31 32 34 37 40 41 42 43 44 45 46 48 49 50 51 52 53 54 55 56 57 58 59\n",
      " 61 62 63 64 65 66 67 68 70 71 72 73 74 75 76 77 79 80 82 83 84 85 86 88\n",
      " 90 91]\n",
      "Valid week range:  [ 0  6  7 15 18 20 33 35 36 38 39 47 60 69 78 81 87 89]\n",
      "Train shape:  (1221238, 264)\n",
      "Valid shape:  (305421, 264)\n",
      "Train week range:  [ 0  1  3  4  5  6  7  8  9 10 11 13 14 15 16 17 18 19 20 22 23 24 25 26\n",
      " 27 29 31 33 35 36 37 38 39 40 41 43 44 45 46 47 50 51 52 53 54 55 57 58\n",
      " 59 60 62 63 64 65 66 67 68 69 71 72 74 75 77 78 79 81 82 83 84 85 87 88\n",
      " 89 90]\n",
      "Valid week range:  [ 2 12 21 28 30 32 34 42 48 49 56 61 70 73 76 80 86 91]\n",
      "Train shape:  (1221224, 264)\n",
      "Valid shape:  (305435, 264)\n",
      "Train week range:  [ 0  2  3  5  6  7  9 10 12 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28\n",
      " 30 32 33 34 35 36 38 39 40 42 43 46 47 48 49 50 51 52 53 54 55 56 59 60\n",
      " 61 62 63 64 66 67 68 69 70 71 72 73 75 76 77 78 79 80 81 82 86 87 88 89\n",
      " 90 91]\n",
      "Valid week range:  [ 1  4  8 11 13 29 31 37 41 44 45 57 58 65 74 83 84 85]\n",
      "Train shape:  (1221378, 264)\n",
      "Valid shape:  (305281, 264)\n",
      "Train week range:  [ 0  1  2  3  4  6  7  8  9 11 12 13 14 15 16 18 20 21 25 29 28 30 31 32\n",
      " 33 34 35 36 37 38 39 40 41 42 43 44 45 47 48 49 51 52 53 54 56 57 58 59\n",
      " 60 61 63 64 65 67 68 69 70 71 73 74 76 78 79 80 81 82 83 84 85 86 87 89\n",
      " 90 91]\n",
      "Valid week range:  [ 5 10 17 19 22 23 24 26 27 46 50 55 62 66 72 75 77 88]\n",
      "Train shape:  (1221740, 264)\n",
      "Valid shape:  (304919, 264)\n"
     ]
    }
   ],
   "source": [
    "# Define the features and target variable\n",
    "X = df_train.drop(columns=[\"target\", \"case_id\",\"WEEK_NUM\"])\n",
    "y = df_train[\"target\"]\n",
    "weeks = df_train[\"WEEK_NUM\"]\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# Define the LightGBM parameters\n",
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"max_depth\": 10,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_bin\": 255,\n",
    "    \"n_estimators\": 1200,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"verbose\": -1,\n",
    "    \"random_state\": 42,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 10,\n",
    "    \"extra_trees\":True,\n",
    "    'num_leaves':64,\n",
    "    \"device\": \"gpu\",\n",
    "}\n",
    "\n",
    "fitted_models = []\n",
    "cv_scores = []\n",
    "\n",
    "# Cross-validation loop to train the model\n",
    "for idx_train, idx_valid in cv.split(X, y, groups=weeks):\n",
    "    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n",
    "    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n",
    "\n",
    "    print(\"Train week range: \", weeks.iloc[idx_train].unique())\n",
    "    print(\"Valid week range: \", weeks.iloc[idx_valid].unique())\n",
    "    \n",
    "    print(\"Train shape: \", X_train.shape)\n",
    "    print(\"Valid shape: \", X_valid.shape)\n",
    "    # \n",
    "    # model = lgb.LGBMClassifier(**params)\n",
    "    # model.fit(\n",
    "    #     X_train, y_train,\n",
    "    #     eval_set=[(X_valid, y_valid)],\n",
    "    #     callbacks=[lgb.log_evaluation(50), lgb.early_stopping(50)]\n",
    "    # )\n",
    "    # \n",
    "    # fitted_models.append(model)\n",
    "    # \n",
    "    # y_pred_valid = model.predict_proba(X_valid)[:, 1]\n",
    "    # auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    # cv_scores.append(auc_score)\n",
    "\n",
    "# model = VotingModel(fitted_models)\n",
    "# print(\"CV AUC scores: \", cv_scores)\n",
    "# print(\"Average CV AUC score: \", sum(cv_scores) / len(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0           0\n1           0\n2           0\n3           0\n4           0\n           ..\n1526654    91\n1526655    91\n1526656    91\n1526657    91\n1526658    91\nName: WEEK_NUM, Length: 1526659, dtype: int64"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weeks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T17:48:39.846423900Z",
     "start_time": "2024-03-23T17:48:39.826408300Z"
    }
   },
   "id": "f14904d8362a25d0"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e0d3f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:28:56.375684Z",
     "iopub.status.busy": "2024-03-12T08:28:56.375350Z",
     "iopub.status.idle": "2024-03-12T08:28:56.576095Z",
     "shell.execute_reply": "2024-03-12T08:28:56.575295Z"
    },
    "papermill": {
     "duration": 0.221706,
     "end_time": "2024-03-12T08:28:56.578675",
     "exception": false,
     "start_time": "2024-03-12T08:28:56.356969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = df_test.drop(columns=[\"WEEK_NUM\"])\n",
    "X_test = X_test.set_index(\"case_id\")\n",
    "\n",
    "lgb_pred = pd.Series(model.predict_proba(X_test)[:, 1], index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7755d0",
   "metadata": {
    "papermill": {
     "duration": 0.018013,
     "end_time": "2024-03-12T08:28:56.615718",
     "exception": false,
     "start_time": "2024-03-12T08:28:56.597705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cfd1ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:28:56.653089Z",
     "iopub.status.busy": "2024-03-12T08:28:56.652741Z",
     "iopub.status.idle": "2024-03-12T08:28:56.669774Z",
     "shell.execute_reply": "2024-03-12T08:28:56.668864Z"
    },
    "papermill": {
     "duration": 0.038543,
     "end_time": "2024-03-12T08:28:56.672019",
     "exception": false,
     "start_time": "2024-03-12T08:28:56.633476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_subm = pd.read_csv(ROOT / \"sample_submission.csv\")\n",
    "df_subm = df_subm.set_index(\"case_id\")\n",
    "\n",
    "df_subm[\"score\"] = lgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1457bdd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:28:56.709821Z",
     "iopub.status.busy": "2024-03-12T08:28:56.709464Z",
     "iopub.status.idle": "2024-03-12T08:28:56.715122Z",
     "shell.execute_reply": "2024-03-12T08:28:56.714218Z"
    },
    "papermill": {
     "duration": 0.026815,
     "end_time": "2024-03-12T08:28:56.717127",
     "exception": false,
     "start_time": "2024-03-12T08:28:56.690312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check null:  False\n"
     ]
    }
   ],
   "source": [
    "print(\"Check null: \", df_subm[\"score\"].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41eda451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:28:56.756438Z",
     "iopub.status.busy": "2024-03-12T08:28:56.755396Z",
     "iopub.status.idle": "2024-03-12T08:28:56.769109Z",
     "shell.execute_reply": "2024-03-12T08:28:56.767939Z"
    },
    "papermill": {
     "duration": 0.035418,
     "end_time": "2024-03-12T08:28:56.771112",
     "exception": false,
     "start_time": "2024-03-12T08:28:56.735694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57543</th>\n",
       "      <td>0.006857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57549</th>\n",
       "      <td>0.028016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57551</th>\n",
       "      <td>0.006491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57552</th>\n",
       "      <td>0.006775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57569</th>\n",
       "      <td>0.079827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            score\n",
       "case_id          \n",
       "57543    0.006857\n",
       "57549    0.028016\n",
       "57551    0.006491\n",
       "57552    0.006775\n",
       "57569    0.079827"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d337c70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:28:56.809690Z",
     "iopub.status.busy": "2024-03-12T08:28:56.809074Z",
     "iopub.status.idle": "2024-03-12T08:28:56.816311Z",
     "shell.execute_reply": "2024-03-12T08:28:56.815623Z"
    },
    "papermill": {
     "duration": 0.02861,
     "end_time": "2024-03-12T08:28:56.818303",
     "exception": false,
     "start_time": "2024-03-12T08:28:56.789693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_subm.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7602123,
     "sourceId": 50160,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1386.18169,
   "end_time": "2024-03-12T08:28:58.035596",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-12T08:05:51.853906",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
